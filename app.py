import os
from dotenv import load_dotenv
import streamlit as st

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage

load_dotenv()

# å°‚é–€å®¶ã®æŒ¯ã‚‹èˆã„ï¼ˆA/Bï¼‰ã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
EXPERT_SYSTEMS = {
	"A": (
		"ã‚ãªãŸã¯æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›®çš„ã€äºˆç®—ã€ç§»å‹•æ‰‹æ®µã€"
		"å­£ç¯€ã‚„å®‰å…¨é¢ã‚’è€ƒæ…®ã—ã€ç¾å®Ÿçš„ã§å…·ä½“çš„ãªæ—…ç¨‹æ¡ˆã‚’æ—¥æœ¬èªã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
		"å¯èƒ½ãªã‚‰æ—¥ç¨‹ã”ã¨ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã€ç›®å®‰è²»ç”¨ã€äºˆç´„ã®ã‚³ãƒ„ã‚‚å«ã‚ã¦ãã ã•ã„ã€‚"
	),
	"B": (
		"ã‚ãªãŸã¯ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›®æ¨™ã€çµŒé¨“ã€ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã‚’è¸ã¾ãˆã€"
		"é”æˆå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’æ—¥æœ¬èªã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
		"çŸ­æœŸ/ä¸­æœŸ/é•·æœŸã®ã‚¹ãƒ†ãƒƒãƒ—ã€å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ã®æ–¹æ³•ã€æƒ³å®šèª²é¡Œã¨å¯¾ç­–ã‚’å«ã‚ã¦ãã ã•ã„ã€‚"
	),
}


def get_openai_api_key() -> str | None:
	"""ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ Streamlit secrets ã‹ã‚‰ OpenAI API ã‚­ãƒ¼ã‚’å–å¾—"""
	key = os.getenv("OPENAI_API_KEY")
	if not key:
		try:
			# st.secrets ã¯è¨­å®šãŒãªã„ã¨ KeyError ã‚’æŠ•ã’ã‚‹å¯èƒ½æ€§ã‚ã‚Š
			key = st.secrets.get("OPENAI_API_KEY")
		except Exception:
			key = None
	return key


def ask_llm(input_text: str, expert_choice: str) -> str:
	"""
	å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶é¸æŠï¼ˆA/Bï¼‰ã‚’å—ã‘å–ã‚Šã€LLMã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚
	"""

	if expert_choice not in EXPERT_SYSTEMS:
		raise ValueError("expert_choice ã¯ 'A' ã¾ãŸã¯ 'B' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")

	api_key = get_openai_api_key()
	if not api_key:
		raise RuntimeError("OpenAI API ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã¾ãŸã¯ st.secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")

	system_msg = EXPERT_SYSTEMS[expert_choice]

	# Lesson8ã®ã‚¹ã‚¿ã‚¤ãƒ«: SystemMessage + HumanMessage ã®ä¼šè©±å±¥æ­´ã‚’LLMã¸
	messages = [
		SystemMessage(content=system_msg),
		HumanMessage(content=input_text),
	]

	# ChatOpenAI: Lesson8ã«æº–æ‹ ã—ã¤ã¤æœ€æ–°APIã§invoke
	llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=api_key)
	ai_response = llm.invoke(messages)
	return ai_response.content.strip()


def main():
	st.set_page_config(page_title="LangChain Ã— Streamlit LLMãƒ‡ãƒ¢", page_icon="ğŸ¤–")
	st.title("LangChain Ã— Streamlit LLMãƒ‡ãƒ¢")

	# ã‚¢ãƒ—ãƒªæ¦‚è¦ã¨æ“ä½œæ–¹æ³•
	st.markdown(
		"""
		**æ¦‚è¦**
		- ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ LangChain çµŒç”±ã§ LLM ã«æ¸¡ã—ã€å›ç­”ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
		- ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ã€Œå°‚é–€å®¶A / å°‚é–€å®¶Bã€ã‚’é¸ã¶ã¨ã€LLMã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå½¹å‰²ï¼‰ãŒåˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™ã€‚

		**æ“ä½œæ–¹æ³•**
		- ãƒ•ã‚©ãƒ¼ãƒ ã«ç›¸è«‡å†…å®¹ï¼ˆå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’è¨˜å…¥
		- å°‚é–€å®¶ç¨®åˆ¥ï¼ˆA/Bï¼‰ã‚’é¸æŠ
		- ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã§å›ç­”ã‚’ç”Ÿæˆ
		"""
	)

	# API ã‚­ãƒ¼ã®æ¡ˆå†…
	st.info(
		"OpenAI API ã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã¾ãŸã¯ Streamlit ã® secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
	)

	# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼ˆA/B ã‚’é¸æŠï¼‰
	expert_choice = st.radio(
		"å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠ",
		options=["A", "B"],
		index=0,
		help="A=æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ / B=ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒ"
	)

	# å°‚é–€å®¶ã®èª¬æ˜
	with st.expander("å°‚é–€å®¶ã®èª¬æ˜", expanded=False):
		st.write("A: æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã®å°‚é–€å®¶ã€‚ç¾å®Ÿçš„ã§å®‰å…¨ãªæ—…ç¨‹ã‚’ææ¡ˆã—ã¾ã™ã€‚")
		st.write("B: ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒã®å°‚é–€å®¶ã€‚è¡Œå‹•å¯èƒ½ãªã‚­ãƒ£ãƒªã‚¢è¨ˆç”»ã‚’ææ¡ˆã—ã¾ã™ã€‚")

	# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
	with st.form("llm_input_form", clear_on_submit=False):
		input_text = st.text_area("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ", placeholder="ç›¸è«‡ã—ãŸã„å†…å®¹ã‚’å…·ä½“çš„ã«æ›¸ã„ã¦ãã ã•ã„ã€‚", height=150)
		submitted = st.form_submit_button("é€ä¿¡")

	if submitted:
		if not input_text.strip():
			st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
			return

		try:
			response = ask_llm(input_text=input_text.strip(), expert_choice=expert_choice)
			st.success("LLMã®å›ç­”")
			st.write(response)
		except Exception as e:
			st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


if __name__ == "__main__":
	main()

